---
title: "Piecewise Regression with NB Error on Simulated Data using BRMS"
author: "Michael Gilchrist"
date: "2023-01-12"
output: pdf_document
---

```{r setup, include=FALSE, }

## Global options
options(digits = 3)

### Knitr specific
knitr::opts_chunk$set(
  warning = TRUE, # show warnings
  message = FALSE, # show messages
  error = TRUE, # do not interrupt generation in case of errors,
  echo = TRUE  # show R code
  fig.width = 8
  fig.path = "Figures/"
)

options("warn" = 1) ## print warnings when they occur

if(interactive()) default::default(.ess.eval) <- list(max.deparse.length=5E1, output = TRUE)

```
# Goal

- Simulate realistic data based on data we have on `motif_count`.
- Fit two piece nb to simulated data using `brms` and possibly `rstan`.

## Recap

While `brms` can build and run the models, there are serious issues

- We get negative `mu` parameters for the NB.
- We get lots of `NaN` in the output
- I am unsure if I'm actually fitting the model as I intend.
  For example, when using two groups for "x0", I don't get two estimates of "x0"
- I have failed to use male as a fundamental grouping beyond the `separate` setting.

# Set up

## Install libraries

```{r, message = FALSE}

# install packages user might not have by replacing FALSE with TRUE

## load libraries
library(stats)
library(MASS) # provides negative binomial fitting:  glm.nb
library(ggplot2)
library(ggpubr)
library(grid)
library(gridExtra)
library(GGally)
library(broom)
library(tidyverse)
library(viridisLite)
library(cmdstanr)
library(rstan)
options(mc.cores = 4) #(parallel::detectCores()-2))
rstan_options(auto_write = TRUE)
library(brms)
library(loo)
library(shinystan)


## options(ggplot2.continuous.colour="viridis",
##        ggplot2.discrete.colour="viridis",
##        ggplot2.scale_fill_discrete = scale_fill_viridis_d,
##        ggplot2.scale_fill_continuous = scale_fill_viridis_c)

library(reshape2)
library(lme4)
library(latex2exp)

```

## Load Data

```{r}
input_dir <- file.path("input")
output_dir <- file.path("output")

load(file.path(input_dir, "data.processing_2022-12-15.Rda"),
     verbose = TRUE)


motif_data
```
# Process Data
## Create Working Dataset

```{r}

filter_data <- TRUE

if(filter_data) {
  males_filtered_disp <- motif_stats_40C %>%
    filter(dispersion < 50) %>%
    pull(male)

  males_filtered_mean <- motif_stats %>%
    filter(mean > 10) %>% # changing from 10 to 40 removes previous male 7 (T258)
    pull(male)

  male_vector <- intersect(males_filtered_mean, males_filtered_disp)
} else {
  male_vector <- motif_data %>% select(male) %>% distinct()
}

data_ind <- motif_data %>%
    filter(male %in% male_vector) %>%
    mutate(male = droplevels(male)) %>%
    mutate(index = as.integer(male)) %>%
    mutate(male = as.character(male)) %>% 
    arrange(index) %>%
    select(male, index, motif_count, temp_target, temp, round, trial_round, date, counter) %>% 
  ##    left_join(index_shape, by = "index") %>%
  mutate()

stats_ind <- motif_stats %>%
    filter(male %in% male_vector) 


data_ind <- data_ind %>% filter(temp < 38) %>%
    group_by(male) %>% mutate(y0_simple.est = mean(motif_count), phi_ind = var(motif_count)/y0_simple.est) %>% ## phi is overdispersion parameter
    ungroup()

summary(data_ind)
n_male <- length(unique(data_ind$male))

## for calculation of 'theta_bar' (size in `rnbinom`) see note in `Set Up Simulate Data`
summary_stats <- data_ind %>% ungroup() %>%  summarize(y0_bar = mean(y0_simple.est), y0_sd = sd(y0_simple.est), phi_bar = median(phi_ind), theta_bar = y0_bar^2/(y0_sd^2 - y0_bar))
comment(summary_stats) <- "summary stats for observed bird motifs"

save(summary_stats, file = file.path(output_dir, "obs_summary_stats.Rda"))




```



## Create Simulated Dataset

- Simulation based on code from "code/2022-12-15_rstan_two.piece.qpoisson.with.simulated.data/rstan_twopiece_fit.various.models.to.simulated.data.Rmd"

From `rnbinom` help
  >  An alternative parametrization (often used in ecology) is by the
  >   _mean_ ‘mu’ (see above), and ‘size’, the _dispersion parameter_,
  >   where ‘prob’ = ‘size/(size+mu)’.  The variance is ‘mu + mu^2/size’
  >   in this parametrization.

So above we can estimate `size = mu^2/(var - mu)`.
We do this above in summary_stats `theta_bar = y0_bar^2/(y0_sd^2 - y0_bar)`.

### Functions Used

```{r}

sim_parms <- function(flag = "uniform_1", n_male = 10, mean_global = 100, sd = 10, n_sd = 2, min = 10, max = 600) {

    mean_low <- mean_global - n_sd * sd
    mean_high <- mean_global + n_sd * sd
    n_low <- floor(n_male/2)
    n_high <- n_male - n_low
    
    switch(flag,
           ## Parameter values are uniform across males within a category (high vs. low)
           uniform_1 = {
               tibble(parm = rep(mean_global, times = n_male), grp = 1L)},
           
           uniform_2 = {
               tibble(parm = c(rep(mean_low, times = n_low),
                              rep(mean_high, times = n_high)),
                      
                      grp =  c(rep(1L, times = n_low), 
                               rep(2L, times = n_high))
                      )},
           ## Parameter values vary between males, but pulled from distribution common to each category (high vs. low)
           ## Note syntax differs from model usage (this would 'be pooled')
           ## Should update model usage
           groups_1 = {
               tibble(parm = rnorm(n_male, mean_global, sd),
                      grp = 1L
                      )},
           groups_2 = {
               tibble(parm = c(rnorm(n_low, mean_low, sd),
                               rnorm(n_high, mean_high, sd)),
                      grp =  c(rep(1L, times = n_low),
                               rep(2L, times = n_high))
                      )}
           ) %>%
        mutate(parm = round(parm, 1)) %>%
        mutate(parm = pmax(min, parm)) %>% ## ensure parm is not below `min`
        mutate(parm = pmin(max, parm)) %>% ## ensure parm is not below `max`
        #mutate(parm = as.integer(parm)) %>%
        slice_sample(n = n_male, replace = FALSE) %>%
        mutate(index = row_number())
}

var_temp_mean <- function(temp_target) {
    ## Returns expected variance in temp_mean given temp_target
    ## numbers from analysis in `code/2023-01-13_temp_target.vs.var/compare.temp_target.vs.var.Rmd`
    var = max(0.891, -5.16 + 0.167 * temp_target)

    return(var)
}

sd_temp_mean <- function(temp_target) {
    sqrt(var_temp_mean(temp_target))
    }

two_piece_model <- function(temp, y0, x0, xmax, theta) {
  ifelse(temp < x0, y0, y0 * (1-(temp-x0)/(xmax-x0)))
}

sim_nb_counts <- function(temp, y0, x0, xmax, theta) {
    ## Calculate expected value given parametes
    mu <- two_piece_mode(temp, y0, x0, xmax, theta)
                                        #print(paste("size: ", size, "count: ", count))
    rnbinom(1, size = theta, mu = mu)
}


sim_qpoisson_counts <- function(temp, y0, x0, xmax, phi) {

    ## Calculate expected value given parametes
    mu <- ifelse(temp < x0, y0, y0 * (1-(temp-x0)/(xmax-x0))) 
    
    ## calculate theta parameter based on mu and phi
    theta = mu/(phi - 1)
    #print(paste("size: ", size, "count: ", count))
    rnbinom(1, size = theta, mu = mu)
    }


```

### Generate Parameter Tibble

- Parameter values in this tibble will be used to create simulated data.

```{r}

data_sim_file <- file.path(output_dir, "data_sim_tbl")
recreate_simulated_data <- FALSE

phi <- summary_stats$phi_bar ## overdispersion parameter
theta <- summary_stats$theta_bar ## size parameter
y0_bar <- summary_stats$y0_bar
y0_sd <- summary_stats$y0_sd
xmax <- 46
n_male <- 12

## Simulate data if it doesn't exist or if desired

if( ! file.exists(data_sim_file) | recreate_simulated_data) {
  ## Generate 'true' parameters
  ## If TRUE, replace estimated y_0 with simulated values,
  ## else use estimates from observed data 
  y_flags <- c("uniform_1", "uniform_2", "groups_1", "groups_2")
  x_flags <- y_flags

  data_sim <- tibble()

  replicates <- c(2, 8, 32)
  temp_target <- c(30, 38, 40, 42, 44)

  set.seed(2022)

  for(sampling_dist in c("qpoisson", "nb")) {
    for(x_flag in x_flags) {
      for(y_flag in y_flags) {
        for(n_reps in replicates) {

          y0_sim <- sim_parms(flag = y_flag, n_male = n_male, mean = y0_bar, sd = y0_sd) %>%
            rename(y0 = parm, yy = grp)
          x0_sim <- sim_parms(flag = x_flag, n_male = n_male, mean = 39, sd = 1, min = 35, max = 45.9)  %>%
            rename(x0 = parm, xx = grp)

          x0_y0_sim <- full_join(x0_sim, y0_sim, by = "index") %>%
            relocate(index) ## move index to first column


          ## Create relevant subset data matrix
          data_parms <- crossing(sampling_dist = sampling_dist,
                                 x0_y0_sim,
                                 temp_target = temp_target,
                                 n_reps = n_reps,
                                 rep = 1:n_reps,
                                 x_flag = x_flag,
                                 y_flag = y_flag)

          data_parms <- data_parms %>%
            rowwise() %>%
            mutate(temp_sd = sd_temp_mean(temp_target),
                   temp_mean = min(rnorm(1, mean = temp_target, sd = temp_sd), 45.9)) %>% 
            select(-temp_sd)

          summary(data_parms)
          
          data_tmp <- switch(sampling_dist,
                             qpoisson = {
                               data_parms %>%
                                 mutate(motif_count= sim_qpoisson_counts(temp_mean, y0, x0, xmax, phi))},
                             nb = {
                               data_parms %>%
                                 mutate(motif_count = sim_nb_counts(temp_mean, y0, x0, xmax, theta))
                             }
                             )
          
          if(nrow(data_sim) == 0) {
            data_sim <- data_tmp
          } else {
            data_sim <- bind_rows(data_sim, data_tmp)
          }
        }
      }
    }
  }

  ## undo 'rowwise'
  data_sim <- data_sim %>% ungroup()

  save(data_sim, file = data_sim_file)
} else {
  load(data_sim_file)
}
```

# Fit Models

## Common Parameters
 
```{r}

iter <- 2000
xmax <- 46
x0max <- xmax - 0.5;
x0min <- 20;

y_xmax <- 0
y0_min <- 10
sd_y0_prior <- 200
alpha_theta_prior <- 10 ## exponential dist scale parameter for overdispersion theta in quasipoisson
alpha_phi_prior <- 0.01 ## gamma dist shape parameter for nb. brms default is 0.01
beta_phi_prior <- 0.01 ## gamma dist rate parameter for nb. brms default is 0.01


## values to use for model predictions
x_for_predictions = seq(25, xmax, length.out = 100)
n_cores <- 4
n_chains <- n_cores
```
## Simulated Data


### Analyze `x ~ groups_1|2, y ~ groups_1|2`
#### Set Up Data
```{r}


x_flag_data <- "groups_2"
y_flag_data <- "groups_2"
sampling_dist <- "nb"
n_r <- 32

data <- data_sim %>% filter(x_flag == x_flag_data,
                            y_flag == y_flag_data,
                            sampling_dist == sampling_dist,
                            n_reps == n_r) %>%
    rename(temp = temp_mean, male = index) %>%
    rename(y = motif_count, x = temp) %>%
    mutate(male = factor(male))

```
#### Fit Model


##### `x0` and `y0` Parameter Structure: Individual

Working with `groups_2` data

```{r}
adapt_delta <- 0.9
flags <- c("groups_1", "groups_2")
models <- c("brms")
flags_x <- flags
flags_y <- flags
N <- length(data)

fit_tbl <- crossing(model = models,
                    x0 = flags_x, y0 = flags_y,
                    desc = "NA_character",
                    y0_group_list = list(NA),
                    x0_group_list = list(NA),
                    fit = list(NA),
                    llik = list(NA),
                    r_eff = list(NA),
                    loo = list(NA)
                    )


## Priors

my_priors <- prior(normal(150, 200), nlpar = "y0", lb = 1) +
    prior(uniform(30, 45.5), lb = 30, ub = 45.5, nlpar = "x0")


model = models[[1]]

for(x_flag in flags_x) {
  for(y_flag in flags_y) {

    ## Set up variables for saving model and fit
    desc <- paste0(model, ": ", x_flag, ", ", y_flag)
    curr_row <- which(fit_tbl$model == model &
                          fit_tbl$x0 == x_flag &
                        fit_tbl$y0 == y_flag)
    fit_tbl[ curr_row, ]$desc <- desc

    print(desc)

    ## Parameter Structure
    x_form <- switch(x_flag,
                    individual = formula(x0 ~ -1 + male), 
                    groups_1 = formula(x0 ~ (1|| male)), # no need for xx when there's only 1 group
                    groups_2 = formula(x0 ~ 1 + (xx|| male))
                    )
                
    y_form <- switch(y_flag,
                    individual = formula(y0 ~ -1 + male), 
                    groups_1 = formula(y0 ~ (1|| male)),
                    groups_2 = formula(y0 ~ 1 + (yy|| male))
                    )
    nlform <- bf(
      y ~  0 - (46 - fmax(x0, x)) * (0 - y0)/(46 - x0),
             x_form,
             y_form,
             nl = TRUE)

    if(FALSE) get_prior(nlform, data = data, family = negbinomial(link = "identity", link_shape = "identity"))


fit <- brm(nlform,
           data = data,
           ## `link` refers to the mapping of the expectation of the distribution: log, sqrt, identity, softplus
           ## link_shape corresponds to `phi` of `stan`'s
           ## Negbinomial_2
           ## Defining `phi = mu/theta` creates a quasipoisson
           ## distribution with overdispersion parameter (1 +theta)
           family = negbinomial(link = "identity", link_shape = "identity"),
           prior = my_priors,
           iter = iter,
           silent = ifelse(interactive(), 1, 2)), # 0, 1, or 2. 1 is default
           control = list(adapt_delta = adapt_delta,
                          max_treedepth = 12,
                          ## Only print out sampling progress if in interactive mode
                          refresh = ifelse(interactive(),max(iter/10, 1), 0)
                          ),
           chains = n_chains,
           cores = n_cores,
           save_model = "brms_two.piece.stan")
      ## Avoid having brms recompile model by defining
      ## model in global environment
      stanfit <- fit
      
      #fit_exp <- expose_functions(fit) , vectorize = TRUE)
      #fit_cr <- add_criterion(fit_exp, c("loo", "waic"))
      print(fit)     
    fit_tbl[ curr_row, ]$fit <- list(fit)

    ## Print and then clear warnings
    warnings(summary)
    warning(immediate. = FALSE)

  }
}

save(file = file.path(output_dir, paste0("fit_tbl_data_", x_flag_data, "_", y_flag_data, "_n32.Rda")), fit_tbl)

```

##### Output from model fits

- Text indicating model is repeatedly recompiled has been removed.


###### Analysis of `groups_1` Data

```{verbatim}

"brms: individual, individual"

STARTING SAMPLER FOR MODEL 'anon_model' NOW.
 Family: negbinomial 
  Links: mu = identity; shape = identity 
Formula: y ~ 0 - (46 - fmax(x0, x)) * (0 - y0)/(46 - x0) 
         x0 ~ -1 + male
         y0 ~ -1 + male
   Data: data (Number of observations: 1920) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
x0_male1     36.71      0.95    34.59    38.31 1.00     3962     2515
x0_male2     39.84      0.73    38.21    41.11 1.00     4141     2758
x0_male3     38.62      0.83    36.95    40.09 1.00     4203     2884
x0_male4     36.28      1.36    33.46    38.56 1.00     3494     2213
x0_male5     38.41      0.91    36.30    39.92 1.00     3652     2013
x0_male6     41.94      0.40    41.13    42.70 1.00     5015     3010
x0_male7     40.62      0.66    39.23    41.81 1.00     3883     2603
x0_male8     39.76      0.54    38.65    40.83 1.00     4593     2903
x0_male9     38.83      0.68    37.33    40.06 1.00     3720     2208
x0_male10    34.97      1.28    32.20    37.23 1.00     3959     2235
x0_male11    38.35      0.92    36.35    39.92 1.00     3594     2494
x0_male12    37.60      0.93    35.60    39.24 1.00     4784     2653
y0_male1    203.65     18.38   172.07   245.09 1.00     4081     2287
y0_male2     64.66      4.94    56.13    75.63 1.00     4234     2683
y0_male3    255.97     21.00   220.31   301.97 1.00     4173     3255
y0_male4     56.43      6.57    45.23    70.94 1.00     3480     2279
y0_male5    138.49     12.72   117.90   166.93 1.00     3438     1854
y0_male6    194.18     10.38   174.98   215.31 1.00     5181     3374
y0_male7     47.21      3.31    41.53    54.58 1.00     4037     2942
y0_male8     66.33      4.11    58.96    75.13 1.00     4298     2202
y0_male9    167.19     12.86   145.12   195.89 1.00     3663     2052
y0_male10    39.47      4.02    32.34    48.28 1.00     3882     2193
y0_male11   135.30     12.28   115.05   163.19 1.00     3690     2485
y0_male12    11.18      1.03     9.44    13.46 1.00     4690     2752

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
shape     3.16      0.11     2.95     3.39 1.00     6356     2791

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).


[1] "brms: individual, groups_1"
Warning: There were 1 divergent transitions after warmup. See
https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup

Family: negbinomial 
  Links: mu = identity; shape = identity 
Formula: y ~ 0 - (46 - fmax(x0, x)) * (0 - y0)/(46 - x0) 
         x0 ~ -1 + male
         y0 ~ (1 || male)
   Data: data (Number of observations: 1920) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~male (Number of levels: 12) 
                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(y0_Intercept)    79.47     17.63    53.35   120.20 1.01     1025     1510

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
x0_male1        36.90      0.89    34.95    38.40 1.00     4360     2100
x0_male2        39.84      0.71    38.34    41.14 1.00     6063     2805
x0_male3        38.90      0.77    37.37    40.22 1.00     5115     2939
x0_male4        36.22      1.38    33.29    38.54 1.00     4729     1931
x0_male5        38.47      0.88    36.52    39.96 1.00     4562     2180
x0_male6        41.96      0.39    41.18    42.70 1.00     5524     2704
x0_male7        40.60      0.68    39.20    41.82 1.00     6539     2973
x0_male8        39.74      0.55    38.63    40.81 1.00     5978     2674
x0_male9        38.89      0.64    37.53    40.06 1.00     4379     2072
x0_male10       34.86      1.29    32.10    37.16 1.00     3517     1535
x0_male11       38.38      0.89    36.52    39.91 1.00     4700     3019
x0_male12       37.57      0.95    35.46    39.24 1.00     6090     2482
y0_Intercept   113.58     23.65    66.58   161.39 1.00      673     1110

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
shape     3.16      0.11     2.95     3.37 1.00     5899     3261

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).


[1] "brms: groups_1, individual"

STARTING SAMPLER FOR MODEL 'anon_model' NOW.
 Family: negbinomial 
  Links: mu = identity; shape = identity 
Formula: y ~ 0 - (46 - fmax(x0, x)) * (0 - y0)/(46 - x0) 
         x0 ~ (1 || male)
         y0 ~ -1 + male
   Data: data (Number of observations: 1920) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~male (Number of levels: 12) 
                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(x0_Intercept)     1.94      0.56     1.11     3.33 1.00     1573     2117

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
x0_Intercept    38.66      0.66    37.30    39.87 1.00     1521     2104
y0_male1       196.56     15.51   169.69   230.59 1.00     5089     2429
y0_male2        65.37      4.86    56.63    75.99 1.00     5114     3014
y0_male3       255.48     20.14   221.03   297.36 1.00     5183     3093
y0_male4        52.41      5.18    44.11    64.23 1.00     4203     3194
y0_male5       137.23     11.29   118.18   162.25 1.00     4677     2431
y0_male6       196.18     10.53   177.03   218.01 1.00     5688     2252
y0_male7        48.15      3.38    42.22    55.27 1.00     5018     2311
y0_male8        66.73      4.08    59.38    75.27 1.00     6890     2734
y0_male9       167.08     12.05   146.34   193.20 1.00     5657     2651
y0_male10       36.45      3.29    30.75    43.43 1.00     4483     2649
y0_male11      134.29     11.14   114.90   158.91 1.00     4292     3117
y0_male12       10.98      0.95     9.26    13.11 1.00     5302     2654

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
shape     3.16      0.11     2.95     3.38 1.00     8311     2839

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).


[1] "brms: groups_1, groups_1"
 Family: negbinomial 
  Links: mu = identity; shape = identity 
Formula: y ~ 0 - (46 - fmax(x0, x)) * (0 - y0)/(46 - x0) 
         x0 ~ (1 || male)
         y0 ~ (1 || male)
   Data: data (Number of observations: 1920) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Group-Level Effects: 
~male (Number of levels: 12) 
                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(x0_Intercept)     1.90      0.56     1.10     3.29 1.00     1520     2195
sd(y0_Intercept)    79.31     17.07    52.91   119.09 1.00     1126     1904

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
x0_Intercept    38.72      0.63    37.41    39.95 1.00     1297     1459
y0_Intercept   113.89     23.82    66.15   161.34 1.00      634     1000

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
shape     3.16      0.11     2.95     3.38 1.00     4387     3042

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).

```

#### Generate useful plots

```{r}

## Define fmax() which is used in the model and needs to be defined within R.
## Ideally this would be done via expose_functions() in `brms`, but that's not working.
gmax <- function(a, b) max(a,b)

fmax <- Vectorize(max)

plot(conditional_effects(fit), points = TRUE)

```

#### Compare Parameter Estimates to Truth





### Cruft
```{r}

} else {

    ## Define parameters based on what's in brms_two.piece.stan
fit <- brm(nlform,
           N = length(data),
           Y = data$y0,
           K_x0 = length(unique(data$x0))
           K_y0 = length(unique(data$y0))
           ## `link` refers to the mapping of the expectation of the distribution: log, sqrt, identity, softplus
           ## link_shape corresponds to `phi` of `stan`'s
           ## Negbinomial_2
           ## Defining `phi = mu/theta` creates a quasipoisson
           ## distribution with overdispersion parameter (1 +theta)
           family = negbinomial(link = "identity", link_shape = "identity"),
           prior = my_priors,
           iter = iter,           
           #control = list(adapt_delta = 0.975),
           save_model = "brms_two.piece.stan")
## Avoid having brms recompile model by defining
## model in global environment
                                        #if(!exists("stanfit"))
}
```

```{r}
stan_file <- "two.piece_nb_1.1.stan"
model_name <- sub(".stan", "", stan_file)

## For debugging
##cmodel <- cmdstan_model(stan_file = stan_file)

## To avoid it being continually recompiled
if(! exists("rstan_model")) {
    rstan_model <-stan_model(file = stan_file,
                             verbose = FALSE,
                             model_name = model_name
                             )
}

model <- models[[1]]

for(x_flag in flags_x) {
    for(y_flag in flags_y) {
            
            desc <- paste0(model, ": ", x_flag, ", ", y_flag)
            curr_row <- which(fit_tbl$model == model &
                              fit_tbl$x0 == x_flag &
                              fit_tbl$y0 == y_flag)
            
            fit_tbl[ curr_row, ]$desc <- desc
            print(desc)
            
            x0_group_list <- list()
            y0_group_list <- list()
            
            switch(x_flag,
                   uniform_1 = {
                       x0_group_list <- data$male %>% unique() %>% as.list()
                   },
                   groups_1 = {
                       ## set up groupings based on 2022-12-20 analysis
                       ## Using male ID's instead index to make code more robust
                       x0_group_list[[1]] <- c("T235", "T237", "T244", "T247", "T257", "T260")
                       x0_group_list[[2]] <- c("T234", "T236", "T243", "T246", "T258")
                   },
                   pooled = {
                       x0_group_list[[1]] <- data$male
                   }
                   )


            switch(y_flag,
                   separate = {
                       y0_group_list <- data$male %>% unique() %>% as.list()
                   },
                   grouping_1 = {
                       ## set up groupings based on 2022-12-20 analysis
                       ## Using male ID's instead index to make code more robust
                       y0_group_list[[1]] <- c("T234", "T243", "T244", "T246", "T258", "T260") 
                       y0_group_list[[2]] <- c("T235", "T236", "T237", "T247", "T257")
                   },
                   pooled = {
                       y0_group_list[[1]] <- data$male
                   }
                   )

            fit_tbl[ curr_row, ]$x0_group_list[[1]] <- x0_group_list

            fit_tbl[ curr_row, ]$y0_group_list[[1]] <- y0_group_list    

            ## Convert lists to a vector of concatenated strings
            ## This will simplify mapping male to an x0/y0 index 
            x0_group <-lapply(x0_group_list, paste, collapse = " ") %>% unlist()
            y0_group <-lapply(y0_group_list, paste, collapse = " ") %>% unlist()

            x0_index <- sapply(as.character(data$male), function(x) str_which(x0_group, x))
            y0_index <- sapply(as.character(data$male), function(x) str_which(y0_group, x))

            if(FALSE) {
                print(x0_index)
                print(y0_index)
            }

            switch(model,
                   rstan = {
                     
                       data_list <-list(x = temp,
                                        y = motif_count,
                                        N = N,
                                        X = length(x0_group),
                                        Y = length(y0_group),
                                        NB = 1,
                                        xx = x0_index,
                                        yy = y0_index,
                                        ## male_index = index,
                                        nbb = rep(1,N),
                                        xmax = xmax,
                                        x0_min = x0min,
                                        x0_max = x0max,
                                        y_xmax = y_xmax,
                                        y0_min = y0_min,
                                        sd_y0_prior = sd_y0_prior,
                                        alpha_theta_prior = alpha_theta_prior,
                                        alpha_phi_prior = alpha_phi_prior,
                                                beta_phi_prior = beta_phi_prior
                                        ##x_for_predictions = x_for_predictions,
                                        ## max threshold value.
                                        ## having it too close to xmax *sometimes* leads to sampling
                                        ## near xmax, but with lower lp and very high E13) b0 values
                                        )
                       
                       fit <- stan(file = stan_file,
                                   model_name = model_name,
                                   data = data_list,
                                   cores = n_cores,
                                   chains = n_chains,
                                   iter = iter,
                                   warmup = floor(iter/2),
                                   verbose = FALSE)
                       
                   },
                   brms = {

                       ## Can't use normal R function within stan
                       ## Need to define functions in stan language
                       ## in a character string that's passed to brms
                       
                       df <- data.frame(
                           x = temp,
                           y = motif_count,                   
                           xx = x0_index,
                           yy = y0_index,
                           id = index
                       )

                       my_priors <- prior(normal(150, 200), nlpar = "y0", lb = 1) +
                           ## Alternatively, to avoid negative initial values (but many divergent
                           ##  transitions), try 
                           ## prior(lognormal(log(150), log(200)), nlpar = "y0", lb = log(10)) +
                           ## same as default, but defining here to document syntax
                           prior(gamma(0.01, 0.01), class = "Intercept", dpar = "shape", lb = 0) +
                           prior(uniform(30, 45.5), lb = 30, ub = 45.5, nlpar = "x0") +
                           prior(exponential(6), class = "sd", nlpar = "x0")
                           ##prior(uniform(0.1, 10), class = "sd", nlpar = "x0", lb = 0.1, ub = 10)
                       ## Following gives unreasonably large sd for x0_intercept
                       ## prior(uniform(0.1, 10), lb = 0.1, ub = 4, class = "sd", group = "xx", nlpar = "x0") +
                       
#                         prior(uniform(0.1, 200), lb = 0.1, ub = 200, class = "sd", group = "yy", nlpar = "y0") #+
        #                 prior(constant(46), nlpar = "xmax")
                       ## Have to hard code xmax = 46 and y0_xmax = 0
                       nlform <- bf(y ~ 0 - (46 - fmax(x0, x)) * (0 - y0)/(46 - x0),
                                    shape ~ 1,
                                    ## I don't think x0 and y0 are correct
                                    ## had 1 + xx, then 1 + (1|xx|id)
                                    ## Might need to use 1|id for pooled
                                    ## x0 ~ 0 + (xx|id) for groupings
                                    x0 ~ 1 + (xx|id), 
                                    y0 ~ 1 + (yy|id),
                                    nl = TRUE)
                       
                       fit <- brm(nlform,
                                  data = df,
                                  ## `link` refers to the mapping of the expectation of the distribution: log, sqrt, identity, softplus
                                  ## link_shape corresponds to `phi` of `stan`'s
                                  ## Negbinomial_2
                                  ## Defining `phi = mu/theta` creates a quasipoisson
                                  ## distribution with overdispersion parameter (1 +theta)
                                  family = negbinomial(link = "identity", link_shape = "identity"),
                                  prior = my_priors,
                                  iter = iter,
                                        #init = 1,
                                  silent = 1, # 1 = default
                                  refresh = 0, # 0 = suppress rstan's sampling progress
                                  ##  From rstanarm
                                  ## > The step size used by the numerical integrator is a function
                                  ## > of adapt_delta in that increasing adapt_delta will result in
                                  ## > a smaller step size and fewer divergences. Increasing
                                  ## > adapt_delta will typically result in a slower sampler, but it
                                  ## > will always lead to a more robust sampler.
                                  ## I get divergent transition warnings even at 0.9999
                                  control = list(adapt_delta = 0.999999), # was 0.975
                                  save_model = "brms_two.piece.stan")
                       ## Avoid having brms recompile model by defining
                       ## model in global environment
                       #if(!exists("stanfit"))
                       stanfit <- fit$fit

                   }
                 )
            print(fit)
            fit_tbl[ curr_row, ]$fit <- list(fit)
        
    }
}


nb_fit_tbl <- fit_tbl

```
